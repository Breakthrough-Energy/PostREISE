{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from powersimdata.scenario.scenario import Scenario\n",
    "\n",
    "from data_processing.azure_blob_uploaders import BlobUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadzone2state = {\n",
    "    \"Bay Area\": \"California\",\n",
    "    \"Central California\": \"California\",\n",
    "    \"Northern California\": \"California\",\n",
    "    \"Southeast California\": \"California\",\n",
    "    \"Southwest California\": \"California\",\n",
    "\n",
    "    \"Florida Panhandle\": \"Florida\",\n",
    "    \"Florida North\": \"Florida\",\n",
    "    \"Florida South\": \"Florida\",\n",
    "\n",
    "    \"Georgia North\": \"Georgia\",\n",
    "    \"Georgia South\": \"Georgia\",\n",
    "\n",
    "    \"Chicago North Illinois\": \"Illinois\",\n",
    "    \"Illinois Downstate\": \"Illinois\",\n",
    "\n",
    "    \"Michigan Northern\": \"Michigan\",\n",
    "    \"Michigan Southern\": \"Michigan\",\n",
    "\n",
    "    \"Minnesota Northern\": \"Minnesota\",\n",
    "    \"Minnesota Southern\": \"Minnesota\",\n",
    "\n",
    "    \"Missouri East\": \"Missouri\",\n",
    "    \"Missouri West\": \"Missouri\",\n",
    "\n",
    "    \"Montana Eastern\": \"Montana\",\n",
    "    \"Montana Western\": \"Montana\",\n",
    "\n",
    "    \"New York City\": \"New York\",\n",
    "    \"Upstate New York\": \"New York\",\n",
    "\n",
    "    \"Western North Carolina\": \"North Carolina\",\n",
    "\n",
    "    \"New Mexico Eastern\": \"New Mexico\",\n",
    "    \"New Mexico Western\": \"New Mexico\",\n",
    "\n",
    "    \"Ohio River\": \"Ohio\",\n",
    "    \"Ohio Lake Erie\": \"Ohio\",\n",
    "\n",
    "    \"Pennsylvania Eastern\": \"Pennsylvania\",\n",
    "    \"Pennsylvania Western\": \"Pennsylvania\",\n",
    "\n",
    "    \"Coast\": \"Texas\",\n",
    "    \"East\": \"Texas\",\n",
    "    \"East Texas\": \"Texas\",\n",
    "    \"El Paso\": \"Texas\", \n",
    "    \"Far West\": \"Texas\",\n",
    "    \"North\": \"Texas\",\n",
    "    \"North Central\": \"Texas\",\n",
    "    \"South\": \"Texas\",\n",
    "    \"South Central\": \"Texas\",\n",
    "    \"Texas Panhandle\": \"Texas\",\n",
    "    \"West\": \"Texas\",\n",
    "\n",
    "    \"Virginia Mountains\": \"Virginia\",\n",
    "    \"Virginia Tidewater\": \"Virginia\",\n",
    "}\n",
    "\n",
    "curtailmentResourceTypes = {\n",
    "    'wind': 'wind_curtailment',\n",
    "    'wind_offshore': 'wind_offshore_curtailment',\n",
    "    'solar': 'solar_curtailment'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interconnects = [\n",
    "    'Eastern',\n",
    "    'Western',\n",
    "    'Texas',\n",
    "]\n",
    "\n",
    "locations = [\n",
    "    'USA',\n",
    "    'Eastern',\n",
    "    'Western',\n",
    "    'Texas',\n",
    "    'Alabama',\n",
    "    'Arizona',\n",
    "    'Arkansas',\n",
    "    'California',\n",
    "    'Colorado',\n",
    "    'Connecticut',\n",
    "    'Delaware',\n",
    "    'Florida',\n",
    "    'Georgia',\n",
    "    \n",
    "    'Idaho',\n",
    "    'Illinois',\n",
    "    'Indiana',\n",
    "    'Iowa',\n",
    "    'Kansas',\n",
    "    'Kentucky',\n",
    "    'Louisiana',\n",
    "    'Maine',\n",
    "    'Maryland',\n",
    "    'Massachusetts',\n",
    "    'Michigan',\n",
    "    'Minnesota',\n",
    "    'Mississippi',\n",
    "    'Missouri',\n",
    "    'Montana',\n",
    "    'Nebraska',\n",
    "    'Nevada',\n",
    "    'New Hampshire',\n",
    "    'New Jersey',\n",
    "    'New Mexico',\n",
    "    'New York',\n",
    "    'North Carolina',\n",
    "    'North Dakota',\n",
    "    'Ohio',\n",
    "    'Oklahoma',\n",
    "    'Oregon',\n",
    "    'Pennsylvania',\n",
    "    'Rhode Island',\n",
    "    'South Carolina',\n",
    "    'South Dakota',\n",
    "    'Tennessee',\n",
    "    'Utah',\n",
    "    'Vermont',\n",
    "    'Virginia',\n",
    "    'Washington',\n",
    "    'West Virginia',\n",
    "    'Wisconsin',\n",
    "    'Wyoming'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_name is pg, curtailment, etc\n",
    "# df can be any df where the index = date in UTC, columns = plant_ids, etc.. Column data must be numeric\n",
    "def resample_by_day(df, id_name, value_name):\n",
    "    # Roll up data by day\n",
    "    df_by_day = df.resample('d').sum()\n",
    "\n",
    "    # Turn timestamps into strings\n",
    "    df_by_day.index = df_by_day.index.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Unpivot data so cols are now timestamp, id_name, value\n",
    "    # If we're looking at PG there are now ~900k rows: 2.5k plants * 366 days \n",
    "    df_by_day = df_by_day.reset_index().melt(id_vars='UTC')\n",
    "\n",
    "    df_by_day.columns = ['timestamp', id_name, value_name]\n",
    "\n",
    "    return df_by_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses loadzone2state value\n",
    "def add_plant_grid_info(grid, plant_by_day):\n",
    "    plant_with_loc = plant_by_day.join(grid.plant[['zone_name', 'type', 'interconnect']], on='plant_id')\n",
    "    plant_with_loc = plant_with_loc.rename(columns={ 'type': 'resource_type', 'zone_name': 'zone' })\n",
    "    \n",
    "    # Replace loadzone with state name\n",
    "    plant_with_loc['zone'] = plant_with_loc['zone'].replace(loadzone2state)\n",
    "\n",
    "    return plant_with_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curtailment_by_day(pg_by_day, wind, solar):\n",
    "    pg_renewables = pg_by_day.loc[\n",
    "        (pg_by_day['resource_type'] == 'solar') \n",
    "        | (pg_by_day['resource_type'] == 'wind') \n",
    "        | (pg_by_day['resource_type'] == 'wind_offshore')\n",
    "    ]\n",
    "    pg_renewables['resource_type'] = pg_renewables['resource_type'].replace(curtailmentResourceTypes)\n",
    "    \n",
    "    wind_by_day = resample_by_day(wind, 'plant_id', 'available')\n",
    "    solar_by_day = resample_by_day(solar, 'plant_id', 'available')\n",
    "    wind_and_solar = pd.concat([solar_by_day, wind_by_day])\n",
    "    \n",
    "    # Note: if a plant is in the wind / solar profile but not in the current scenario's grid, we discard it\n",
    "    pg_renewables = pg_renewables.merge(wind_and_solar, how=\"left\", on=['plant_id', 'timestamp'])\n",
    "    \n",
    "    pg_renewables['curtailment'] = pg_renewables['available'] - pg_renewables['pg']\n",
    "    pg_renewables = pg_renewables.drop(columns=['pg', 'available'])\n",
    "    \n",
    "    return pg_renewables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Format of output:\n",
    "{\n",
    "    Arizona: {\n",
    "        coal: [\n",
    "            { x: '2016-01-01', y: 1234 },\n",
    "            { x: '2016-01-02', y: 1812 },\n",
    "            ...\n",
    "        ],\n",
    "        wind: { \n",
    "            ... \n",
    "        }, ...\n",
    "    },\n",
    "    Washington: {\n",
    "    ...\n",
    "    }, ...\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "# uses external locations value\n",
    "def create_dict_of_plant_loc(plant_by_day, value_name):\n",
    "    plant_dict = {}\n",
    "    yearly_plant_dict = {}\n",
    "    \n",
    "    for location in locations:\n",
    "        plant_dict[location] = {}\n",
    "        yearly_plant_dict[location] = {}\n",
    "        \n",
    "        groupby_cols = [\n",
    "            'timestamp', \n",
    "            'resource_type'\n",
    "        ]\n",
    "        if location == 'USA':\n",
    "            plant_by_loc = plant_by_day.drop(columns=['plant_id', 'zone', 'interconnect'])\n",
    "        elif location in interconnects:\n",
    "            groupby_cols.append('interconnect')\n",
    "            plant_by_loc = plant_by_day.loc[(plant_by_day['interconnect'] == location)]\n",
    "            plant_by_loc = plant_by_loc.drop(columns=['plant_id', 'zone'])\n",
    "        else:\n",
    "            groupby_cols.append('zone')\n",
    "            plant_by_loc = plant_by_day.loc[(plant_by_day['zone'] == location)]\n",
    "            plant_by_loc = plant_by_loc.drop(columns=['plant_id'])\n",
    "\n",
    "        # Sum values\n",
    "        plant_by_loc = plant_by_loc.groupby(groupby_cols).sum()\n",
    "        plant_by_loc = plant_by_loc.reset_index()\n",
    "        # Change from MWh to GWh. Also adding 0 prevents -0.0\n",
    "        plant_by_loc[value_name] = plant_by_loc[value_name].apply(lambda x: round(x/1000, 2) + 0) \n",
    "\n",
    "        # split by resource type and add each to pg\n",
    "        resource_types = plant_by_loc.resource_type.unique()\n",
    "        for resource_type in resource_types:\n",
    "            resource_type_df = plant_by_loc.loc[(plant_by_loc['resource_type'] == resource_type)]\n",
    "            resource_type_df = resource_type_df.rename(columns={ 'timestamp': 'x', value_name: 'y' })\n",
    "\n",
    "            # example result: [ { x: '2016-01-23', y: 12345.67 }, ... ]\n",
    "            plant_dict[location][resource_type] = resource_type_df[['x', 'y']].to_dict('records')\n",
    "            yearly_plant_dict[location][resource_type] = round(resource_type_df['y'].sum(), 2)\n",
    "    return plant_dict, yearly_plant_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_plant_dict(data_type, time, plant_loc_dict, scenario_id, blob_client, path, version):\n",
    "    for location in plant_loc_dict:\n",
    "        # Create local path if it doesn't exist\n",
    "        local_save_path=f\"{path}/{version}/{scenario_id}/{time}/{location}\"\n",
    "        Path(local_save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        blob_path = f\"{version}/{scenario_id}/{time}/{location}\"\n",
    "\n",
    "        blob_client.upload_dict_as_json_gzip(\n",
    "            plant_loc_dict[location], \n",
    "            f\"{local_save_path}/{data_type}.json.gzip\",\n",
    "            f\"{blob_path}/{data_type}.json\");\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_upload_plant_dicts(scenario_id, blob_client, path, version):\n",
    "    print(f\"\\nStarting scenario {scenario_id}\\n\")\n",
    "    s = Scenario(str(scenario_id))\n",
    "    grid = s.state.get_grid()\n",
    "    pg = s.state.get_pg()\n",
    "    wind = s.state.get_wind()\n",
    "    solar = s.state.get_solar()\n",
    "    \n",
    "    pg_by_day = resample_by_day(pg, 'plant_id', 'pg')\n",
    "    pg_by_day = add_plant_grid_info(grid, pg_by_day)\n",
    "    \n",
    "    curtailment_by_day = get_curtailment_by_day(pg_by_day, wind, solar)\n",
    "    \n",
    "    print(\"\\nGrouping data by location\")\n",
    "    daily_pg_loc_dict, yearly_pg_loc_dict = create_dict_of_plant_loc(pg_by_day, 'pg')\n",
    "    daily_cur_loc_dict, yearly_cur_loc_dict = create_dict_of_plant_loc(curtailment_by_day, 'curtailment')\n",
    "    \n",
    "    print(\"\\nUploading data\\n\")\n",
    "    upload_plant_dict('pg', 'daily', daily_pg_loc_dict, scenario_id, blob_client, path, version)\n",
    "    upload_plant_dict('pg', 'yearly', yearly_pg_loc_dict, scenario_id, blob_client, path, version)\n",
    "    upload_plant_dict('curtailment', 'daily', daily_cur_loc_dict, scenario_id, blob_client, path, version)\n",
    "    upload_plant_dict('curtailment', 'yearly', yearly_cur_loc_dict, scenario_id, blob_client, path, version)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "version = 'v1' # increment me if changing format!\n",
    "path = './tmp_nivo_data' # Don't include slash at the end\n",
    "scenario_ids = [\n",
    "    '1705', '1724', '1723', '1270', # macro grid\n",
    "    '1152', '1151', '1149', # USA collab\n",
    "    '1099', '1098', '1097', # USA independent\n",
    "    '1206', '1205', '1204', # USA collab w/ storage\n",
    "    '1244', '1245', '1257', # collab w/ renewables at retirements\n",
    "    '1362', '1361', '1338', # offshore wind\n",
    "    '824', '823'            # historical\n",
    "]\n",
    "conn_str = os.environ.get(\"BLOB_STORAGE_CONN_STR\")\n",
    "blob_client = BlobUtil(conn_str, 'grid-data')\n",
    "\n",
    "for scenario_id in scenario_ids:\n",
    "    create_and_upload_plant_dicts(scenario_id, blob_client, path, version)\n",
    "    \n",
    "print(\"\\nfinished!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
